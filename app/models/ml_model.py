"""
Wrapper pour le mod√®le XGBoost de pr√©diction d'attrition
Gestion du chargement, des pr√©dictions et de l'explicabilit√©
IMPORTANT: Adapt√© √† l'encodage OneHot du Projet 4
"""

import joblib
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
import os
from pathlib import Path
import logging
from datetime import datetime
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

from app.models.schemas import EmployeeData, PredictionResult
from app.core.config import settings

logger = logging.getLogger(__name__)

class MLModel:
    """
    Wrapper pour le mod√®le XGBoost de pr√©diction d'attrition des employ√©s
    Adapt√© √† l'encodage OneHot utilis√© dans le Projet 4
    """
    
    def __init__(self):
        self.model = None
        self.model_version = settings.MODEL_VERSION
        self.threshold = 0.514  # Seuil optimal de votre Projet 4
        
        # Encodeurs (charg√©s depuis les fichiers sauvegard√©s du Projet 4)
        self.onehot_encoder = None
        self.ordinal_encoder = None
        self.final_column_names = None
        self.model_info = None
        
        # Variables pour l'encodage
        self.variables_catego = ['departement', 'domaine_etude', 'poste', 'statut_marital']
        self.is_loaded = False
        
    def _load_encoders(self):
        """
        Charge les encodeurs sauvegard√©s depuis le Projet 4
        """
        try:
            models_dir = Path(settings.MODEL_PATH).parent
            
            # Chargement des encodeurs
            onehot_path = models_dir / 'onehot_encoder.pkl'
            ordinal_path = models_dir / 'ordinal_encoder.pkl'
            columns_path = models_dir / 'final_column_names.pkl'
            info_path = models_dir / 'model_info.pkl'
            
            if not all([onehot_path.exists(), ordinal_path.exists(), columns_path.exists()]):
                raise FileNotFoundError(
                    f"Encodeurs manquants dans {models_dir}. "
                    f"Ex√©cutez d'abord le script de sauvegarde dans le Projet 4."
                )
            
            self.onehot_encoder = joblib.load(onehot_path)
            self.ordinal_encoder = joblib.load(ordinal_path)
            self.final_column_names = joblib.load(columns_path)
            
            if info_path.exists():
                self.model_info = joblib.load(info_path)
            
            logger.info(f"‚úÖ Encodeurs charg√©s avec succ√®s")
            logger.info(f"üìä Nombre de features finales: {len(self.final_column_names)}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement des encodeurs: {e}")
            raise e
        
    def load_model(self) -> bool:
        """
        Charge le mod√®le XGBoost et les encodeurs depuis les fichiers .pkl
        """
        try:
            model_path = Path(settings.MODEL_PATH)
            
            if not model_path.exists():
                raise FileNotFoundError(f"Mod√®le non trouv√©: {model_path}")
            
            # Chargement du mod√®le XGBoost
            self.model = joblib.load(model_path)
            
            # Chargement des encodeurs
            self._load_encoders()
            
            self.is_loaded = True
            
            logger.info(f"‚úÖ Mod√®le charg√© avec succ√®s depuis {model_path}")
            logger.info(f"üìä Type de mod√®le: {type(self.model)}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
            raise e
    
    def _preprocess_employee_data(self, employee: EmployeeData) -> np.ndarray:
        """
        Pr√©processe les donn√©es d'un employ√© selon l'encodage du Projet 4
        """
        try:
            # Conversion en dictionnaire
            data_dict = employee.dict()
            
            # Cr√©er un DataFrame avec une seule ligne
            df = pd.DataFrame([data_dict])
            
            # 1. Encodage binaire pour heure_supplementaires
            df.loc[df['heure_supplementaires'] == 'Non', 'heure_supplementaires'] = 0
            df.loc[df['heure_supplementaires'] == 'Oui', 'heure_supplementaires'] = 1
            df['heure_supplementaires'] = df['heure_supplementaires'].astype(int)
            
            # 2. Encodage binaire pour genre (adapter selon vos donn√©es d'entr√©e)
            # Note: Votre sch√©ma Pydantic utilise "Homme"/"Femme" mais votre code "M"/"F"
            # Adaptation n√©cessaire:
            df.loc[df['genre'] == 'Femme', 'genre'] = 0
            df.loc[df['genre'] == 'Homme', 'genre'] = 1
            df['genre'] = df['genre'].astype(int)
            
            # 3. augementation_salaire_precedente reste float (c'est d√©j√† un pourcentage)
            # Pas de transformation n√©cessaire
            
            # 4. Encodage ordinal pour frequence_deplacement
            # Adapter les valeurs du sch√©ma vers vos valeurs d'entra√Ænement
            freq_mapping = {
                'Pas_de_Voyage': 'Aucun',
                'Voyage_Rare': 'Occasionnel', 
                'Voyage_Fr√©quent': 'Frequent'
            }
            df['frequence_deplacement'] = df['frequence_deplacement'].map(freq_mapping)
            df[['frequence_deplacement']] = self.ordinal_encoder.transform(df[['frequence_deplacement']])
            
            # 5. Encodage OneHot pour les variables nominales
            df_categorical = df[self.variables_catego]
            df_encoded = self.onehot_encoder.transform(df_categorical)
            
            # Cr√©er DataFrame avec les nouvelles colonnes
            feature_names = self.onehot_encoder.get_feature_names_out(self.variables_catego)
            df_onehot = pd.DataFrame(df_encoded, columns=feature_names, index=df.index)
            
            # Supprimer les colonnes originales et concatener les encod√©es
            df = df.drop(self.variables_catego, axis=1)
            df = pd.concat([df, df_onehot], axis=1)
            
            # Supprimer la variable cible si elle existe
            if 'a_quitte_l_entreprise' in df.columns:
                df = df.drop('a_quitte_l_entreprise', axis=1)
            
            # R√©organiser les colonnes selon l'ordre d'entra√Ænement
            if self.final_column_names:
                # S'assurer que toutes les colonnes attendues sont pr√©sentes
                missing_cols = set(self.final_column_names) - set(df.columns)
                if missing_cols:
                    logger.error(f"Colonnes manquantes apr√®s encodage: {missing_cols}")
                    raise ValueError(f"Colonnes manquantes: {missing_cols}")
                
                # R√©organiser dans le bon ordre
                df = df[self.final_column_names]
            
            # Conversion en array NumPy
            return df.values
            
        except Exception as e:
            logger.error(f"Erreur lors du pr√©processing: {e}")
            logger.error(f"Colonnes disponibles: {df.columns.tolist() if 'df' in locals() else 'DataFrame non cr√©√©'}")
            if hasattr(self, 'final_column_names') and self.final_column_names:
                logger.error(f"Colonnes attendues: {self.final_column_names[:10]}...")
            raise e
    
    def predict_single(self, employee: EmployeeData, employee_id: Optional[str] = None) -> PredictionResult:
        """
        Effectue une pr√©diction pour un seul employ√©
        """
        if not self.is_loaded:
            raise RuntimeError("Le mod√®le n'est pas charg√©")
        
        try:
            # Pr√©processing
            X = self._preprocess_employee_data(employee)
            
            # Pr√©diction des probabilit√©s
            probabilities = self.model.predict_proba(X)[0]
            prob_stay = probabilities[0]  # Probabilit√© de rester (classe 0)
            prob_quit = probabilities[1]  # Probabilit√© de partir (classe 1)
            
            # D√©cision bas√©e sur le seuil
            prediction = "Oui" if prob_quit >= self.threshold else "Non"
            
            # Niveau de confiance
            confidence_level = self._get_confidence_level(max(prob_stay, prob_quit))
            
            # Facteurs de risque (basique, peut √™tre am√©lior√© avec SHAP)
            risk_factors = self._identify_risk_factors(employee)
            
            return PredictionResult(
                employee_id=employee_id,
                prediction=prediction,
                probability_quit=round(prob_quit, 4),
                probability_stay=round(prob_stay, 4),
                confidence_level=confidence_level,
                risk_factors=risk_factors,
                model_version=self.model_version,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {e}")
            raise e
    
    def predict_batch(self, employees: List[EmployeeData]) -> List[PredictionResult]:
        """
        Effectue des pr√©dictions pour plusieurs employ√©s
        """
        if not self.is_loaded:
            raise RuntimeError("Le mod√®le n'est pas charg√©")
        
        predictions = []
        for i, employee in enumerate(employees):
            try:
                prediction = self.predict_single(employee, employee_id=f"emp_{i+1}")
                predictions.append(prediction)
            except Exception as e:
                logger.error(f"Erreur pour l'employ√© {i+1}: {e}")
                # Continuer avec les autres employ√©s
                continue
        
        return predictions
    
    def _get_confidence_level(self, max_probability: float) -> str:
        """
        D√©termine le niveau de confiance bas√© sur la probabilit√© maximale
        """
        if max_probability >= 0.8:
            return "√âlev√©"
        elif max_probability >= 0.6:
            return "Moyen"
        else:
            return "Faible"
    
    def _identify_risk_factors(self, employee: EmployeeData) -> List[str]:
        """
        Identifie les facteurs de risque basiques
        Cette fonction peut √™tre am√©lior√©e avec SHAP values
        """
        risk_factors = []
        
        # R√®gles heuristiques basiques
        if employee.satisfaction_employee_environnement <= 3:
            risk_factors.append("Satisfaction environnement tr√®s faible")
        
        if employee.satisfaction_employee_nature_travail <= 3:
            risk_factors.append("Satisfaction travail tr√®s faible")
        
        if employee.heure_supplementaires == "Oui":
            risk_factors.append("Heures suppl√©mentaires fr√©quentes")
        
        if employee.augementation_salaire_precedente == "Non":
            risk_factors.append("Pas d'augmentation r√©cente")
        
        if employee.annees_depuis_la_derniere_promotion >= 5:
            risk_factors.append("Pas de promotion depuis longtemps")
        
        if employee.distance_domicile_travail >= 30:
            risk_factors.append("Distance domicile-travail importante")
        
        return risk_factors[:5]  # Limiter √† 5 facteurs principaux
    
    def get_model_info(self) -> Dict:
        """
        Retourne les informations sur le mod√®le
        """
        
        base_info = {
            "model_name": "XGBoost Employee Attrition Classifier",
            "model_type": "XGBoost Classifier", 
            "version": self.model_version,
            "threshold": self.threshold,
            "is_loaded": self.is_loaded,
            "encoding": "OneHot pour variables nominales, Ordinal pour fr√©quence",
        }
        
        # Ajouter les informations du Projet 4 si disponibles
        if self.model_info:
            base_info.update({
                "original_features": self.model_info.get('original_features_count', 27),
                "encoded_features": self.model_info.get('final_features_count', 'Unknown'),
                "categorical_variables_encoded": self.model_info.get('categorical_variables_encoded', []),
            })
        elif self.final_column_names:
            base_info.update({
                "original_features": 27,
                "encoded_features": len(self.final_column_names),
                "categorical_variables_encoded": self.variables_catego,
            })
        
        # M√©triques r√©elles du mod√®le avec validation crois√©e stratifi√©e
        base_info["performance_metrics"] = {
            "accuracy": 0.8588,          # CV moyenne
            "accuracy_std": 0.0220,      # √âcart-type CV
            "precision": 0.5654,         # CV moyenne  
            "precision_std": 0.0701,     # √âcart-type CV
            "recall": 0.5684,            # CV moyenne
            "recall_std": 0.0678,        # √âcart-type CV
            "f1_score": 0.5656,          # CV moyenne
            "f1_std": 0.0638,            # √âcart-type CV
            "roc_auc": 0.8252,           # CV moyenne
            "roc_auc_std": 0.0212        # √âcart-type CV
        }
        
        return base_info
    
    def health_check(self) -> Dict[str, bool]:
        """
        V√©rifie la sant√© du mod√®le
        """
        return {
            "model_loaded": self.is_loaded,
            "model_file_exists": os.path.exists(settings.MODEL_PATH),
            "encoders_loaded": self.onehot_encoder is not None and self.ordinal_encoder is not None,
            "column_names_loaded": self.final_column_names is not None,
            "all_encoder_files_exist": self._check_encoder_files_exist()
        }
        
    def _check_encoder_files_exist(self) -> bool:
        """V√©rifie que tous les fichiers d'encodeurs existent"""
        try:
            models_dir = Path(settings.MODEL_PATH).parent
            required_files = [
                'onehot_encoder.pkl',
                'ordinal_encoder.pkl', 
                'final_column_names.pkl'
            ]
            return all((models_dir / f).exists() for f in required_files)
        except:
            return False